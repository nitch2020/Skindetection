# Skindetection
Determiner les caracteristiques des pixels peau et non peau de l'image dans l'espace de couleur LAB
# RESUME
Le systÃ¨me de dÃ©tection de la peau se compose de deux phases : phase d'apprentissage, dÃ©tection de la peau Tout d'abord, la phase d'apprentissage implique diffÃ©rentes Ã©tapes telles que la sÃ©lection d'ensembles de donnÃ©es d'images de peau, la sÃ©lection de l'espace
colorimÃ©trique appropriÃ© et l'identification des paramÃ¨tres pour le classificateur de peau. La deuxiÃ¨me phase est la dÃ©tection de la peau. Il identifie le pixel de peau Ã  partir de caractÃ©ristiques de peau formÃ©es donnÃ©es. Dans cette phase, l'image est transformÃ©e en un espace colorimÃ©trique diffÃ©rent LAB. Ensuite, la caractÃ©ristique est extraite pour reprÃ©senter la rÃ©gion de la peau. Les fonctionnalitÃ©s sont utilisÃ©es pour classer les pixels en pixels de peau ou non. Et enfin la reprÃ©sentation des histogrammes peau et non peau.La dÃ©tection de la peau est basÃ©e sur l'histogramme. En rÃ©alitÃ© on aura 2 histogrammes: un histogramme qui prÃ©sente les pixels peau et un autre qui prÃ©sente les pixels non peau.
liens base images d'entraÃ®nement , de test et leurs masques: https://drive.google.com/drive/folders/1L5-z4q1nmLfkJkX4UyCFjgQR_hzy_lDO?usp=sh
aring
# La dÃ©tection de la couleur de la peau humaine est importante dans de nombreuses applications. Il existe diverses applications basÃ©es sur la peau dans plusieurs domaines, Ã  savoir l'analyse des gestes, la reconnaissance faciale, le suivi des personnes et la dÃ©tection de la nuditÃ©, la rÃ©cupÃ©ration d'images basÃ©e sur le contenu. En effet, dans le cadre du cours de vision par ordinateur, cette tÃ¢che nous Ã  Ã©tÃ© assignÃ©e. Et pour parvenirÃ  des rÃ©sultats attendus, nous avons utilisÃ© plusieurs techniques de vision par ordinateur en exploitant la librairie Opencv de Python. Nous allons donc vous prÃ©senter
les diffÃ©rentes Ã©tapes de ce travail dans la suite de ce document.
# OUTILS UTILISÃ‰S
â¢ Opencv: Open Source Computer Vision. Câ€™est une bibliothÃ¨que graphique libre spÃ©cialisÃ©e dans le traitement dâ€™images. Elle nous a permis entre autre de lire nos images, de les afficher, de passer dâ€™un espace de couleur Ã  un autre et bien dâ€™autres taches.
â¢ Numpy: câ€™est la bibliothÃ¨que la plus populaire de calcul scientifique en python. Elle nous a principalement servi pour la gestion de nos tableaux dâ€™images.
â¢ Matplotlib: câ€™est une librairie comprÃ©hensive pour crÃ©er des visualisations statiques, animÃ©es et interactives en python.
â¢ Colab: câ€™est un produit de google search qui permet dâ€™Ã©crire et d'exÃ©cuter le code python de son choix par le biais du navigateur. Câ€™est un environnement
particuliÃ¨rement adaptÃ© au machine learning et lâ€™analyse de donnÃ©es.
# IMPLEMENTATION DU MODELE
Pour rÃ©aliser ce projet, nous avons utilisÃ© une base d'images contenant des exemples de pixels peau et de
pixels non-peau accessible Ã  travers ce lien suivant: https://drive.google.com/uc?id=1MnBW_OJqrTmzwc23YI5NK_y_l4zk9JGJ
Cette base d'images contient des images d'apprentissage pour entraÃ®ner notre modÃ¨le (train) et une base d'images de test (test) pour valider les rÃ©sultats. Chaque exemple a une image d'origine et un masque peau correspondant. En outre, nous avons collectÃ© dâ€™autres images Ã  travers le net pour renforcer
l'entraÃ®nement de notre modÃ¨le et ces images sont pour la plupart des images non peau, permetant ainsi d'augmenter la probabilitÃ© des pixels non peau.
lien:https://drive.google.com/drive/folders/1S31oJ8es5MkR9EAlryVXDOaZvlPsBLEo?usp=sharing
# Etape 1: RÃ©cupÃ©ration des images et masques dans des tableaux
AprÃ¨s avoir Ã©tabli notre base dâ€™image, nous crÃ©ons un tableau dans lequel on ajoute chacune des images originales d'entraÃ®nement et un autre tableau dans lequel on ajoute le masque de chaque image. GrÃ¢ce Ã  la mÃ©thode shape pour les tableaux Ã  n dimensionsde numpy, nous pouvons visualiser les caractÃ©ristiques des tableaux obtenus.
# Ã‰tape 2: Afficher quelques images et leurs masques
Pour celÃ  nous rÃ©cupÃ©rons une sÃ©rie d'images de faÃ§on alÃ©atoire Ã  chaque exÃ©cution. Ensuite nous les affichons grÃ¢ce Ã  certaines mÃ©thodes de matplotlib tel que â€œsuplotâ€ et la mÃ©thode â€œimshowâ€ de opencv.
# Etape 3: Changement de lâ€™espace colorimÃ©trique (RGB to LAB)
# RVB fonctionne sur trois canaux : rouge, vert et bleu. LAB est une conversion des mÃªmes informations en un composant de luminositÃ© L* et deux composants de couleur - a* et b*.Danscette Ã©tape on change lâ€™espace de couleur de lâ€™image en passant de lâ€™espace RGB Ã  lâ€™espace Lab grace Ã  la fonction de opencv cv.COLOR_RGB2LAB.
Ã‰tape 4: RÃ©cupÃ©ration et rÃ©duction dans l'espace Lab avec les intervalles de a et b convertis 
Dans cette partie, aprÃ¨s avoir converti nos images dans lâ€™espace LAB, on utilise seulement les canaux a et b sans tenir compte du canal L pour la luminance. Ensuite on procÃ¨de Ã  la rÃ©duction de la quantification, c'est-Ã -dire de rÃ©duire lâ€™intervalle des valeurs de pixels dans chaque canal.
# Ã‰tape 7: Calcul des histogrammes peau et non peau
Cette partie consiste Ã  utiliser les images quâ€™on a converties et rÃ©duire dans lâ€™espace Lab et leur masque pour calculer les histogrammes peau et non peau. Les histogrammes permettent de dÃ©finir les valeurs de pixels correspondant Ã  la peau et les valeurs de pixels non peau Ã  partir dâ€™une valeur seuil.
A partir du calcul des histogrammes peau et non peau nous avons calculÃ© le nombre total des pixels peau et le nombre total des pixels non peau.
ProcÃ©dÃ©: Pour chaque images donnÃ©e, on prend Ã©galement le masque correspondant et on parcours les pixels de lâ€™image et de son masque tel que pour chaque pixel du masque supÃ©rieur Ã  la valeur seuil, le pixel est classÃ© peau, pour chaque valeur de pixel du masque infÃ©rieur Ã  la valeur seuil, le pixel est classÃ© non peau.
# Ã‰tape 6: DÃ©tection de la peau dans les images
A cette Ã©tape, plusieurs mÃ©thodes sont possibles pour dÃ©tecter la peau dans lâ€™image. Nous avons choisi la mÃ©thode de Classifieur BayÃ©sien. Cette mÃ©thode tient en compte les rÃ©sultats que nous avons obtenus de nos histogrammes prÃ©cÃ©demment. En effet, on dÃ©termine Ã  partir de lâ€™histogramme la probabilitÃ© quâ€™un pixel soit peau ou non peau en fonction de sa couleur. Ensuite on utilise la formule suivant pour la dÃ©tection:
ğ‘(ğ‘ğ‘’ğ‘ğ‘¢|ğ‘) = ğ‘(ğ‘|ğ‘ğ‘’ğ‘ğ‘¢)ğ‘(ğ‘ğ‘’ğ‘ğ‘¢)/(ğ‘(ğ‘|ğ‘ğ‘’ğ‘ğ‘¢)ğ‘(ğ‘ğ‘’ğ‘ğ‘¢) + ğ‘(ğ‘|Â¬ğ‘ğ‘’ğ‘ğ‘¢)ğ‘(Â¬ğ‘ğ‘’ğ‘ğ‘¢))
ğ‘(Â¬ğ‘ğ‘’ğ‘ğ‘¢|ğ‘) = ğ‘(ğ‘|Â¬ğ‘ğ‘’ğ‘ğ‘¢)ğ‘(Â¬ğ‘ğ‘’ğ‘ğ‘¢)/(ğ‘(ğ‘|Â¬ğ‘ğ‘’ğ‘ğ‘¢)ğ‘(Â¬ğ‘ğ‘’ğ‘ğ‘¢) + ğ‘(ğ‘|ğ‘ğ‘’ğ‘ğ‘¢)ğ‘(ğ‘ğ‘’ğ‘ğ‘¢))
Ces deux probabilitÃ©s sont comparÃ©es par rapport Ã  un seuil s (0 < s < 1). Le pixel est dit pixel peau si la contrainte suivante est vÃ©rifiÃ©e :
ğ‘(ğ‘ ğ‘˜ğ‘–ğ‘›|ğ‘)/ğ‘(Â¬ğ‘ ğ‘˜ğ‘–ğ‘›|ğ‘)>s
